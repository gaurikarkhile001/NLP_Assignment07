{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A) Non-Negative Matrix Factorization (NMF) for Topic Modeling\n",
        "\n",
        "ðŸ“˜ Theory (Short):\n",
        "\n",
        "NMF is used to extract topics from a collection of documents.\n",
        "\n",
        "It decomposes a document-term matrix into:\n",
        "\n",
        "W (topics per document)\n",
        "\n",
        "H (words per topic)\n",
        "\n",
        "Useful to understand hidden themes in text.\n",
        "\n",
        "Reconstruction Error measures how well the model fits the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic 1: numpy, like, powerful, pandas, python\n",
            "Topic 2: market, economic, crashed, slowdown, stock\n",
            "Reconstruction Error: 1.6737376756861646\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Sample documents\n",
        "docs = [\n",
        "    \"I love programming in Python. Python is great for data science.\",\n",
        "    \"The stock market crashed due to economic slowdown.\",\n",
        "    \"Machine learning and AI are transforming technology.\",\n",
        "    \"Investors are cautious about the global economy.\",\n",
        "    \"Python libraries like Numpy and Pandas are powerful.\"\n",
        "]\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(docs)\n",
        "\n",
        "# Apply NMF\n",
        "nmf = NMF(n_components=2, random_state=42)\n",
        "W = nmf.fit_transform(X)\n",
        "H = nmf.components_\n",
        "\n",
        "# Show top words per topic\n",
        "words = vectorizer.get_feature_names_out()\n",
        "for topic_idx, topic in enumerate(H):\n",
        "    top_words = [words[i] for i in topic.argsort()[-5:]]\n",
        "    print(f\"Topic {topic_idx+1}: {', '.join(top_words)}\")\n",
        "\n",
        "# Reconstruction error\n",
        "print(\"Reconstruction Error:\", nmf.reconstruction_err_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "B) WordNet for Word Sense Disambiguation (WSD)\n",
        "\n",
        "ðŸ“˜ Theory (Short):\n",
        "\n",
        "WordNet is a large lexical database of English.\n",
        "\n",
        "WSD (Word Sense Disambiguation) selects the correct meaning of a word in context.\n",
        "\n",
        "Example: \"bank\" â†’ river bank or financial bank?\n",
        "\n",
        "Use Lesk algorithm from nltk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Gauri\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\Gauri\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Gauri\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Sense: Synset('savings_bank.n.02')\n",
            "Definition: a container (usually with a slot in the top) for keeping money at home\n"
          ]
        }
      ],
      "source": [
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sentence with ambiguous word \"bank\"\n",
        "sentence = \"He went to the bank to deposit money\"\n",
        "word = \"bank\"\n",
        "\n",
        "# Disambiguation using Lesk\n",
        "context = word_tokenize(sentence)\n",
        "sense = lesk(context, word)\n",
        "\n",
        "print(\"Best Sense:\", sense)\n",
        "print(\"Definition:\", sense.definition())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
